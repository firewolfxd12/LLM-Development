# Resources

Created by: Nick Durbin
Created time: June 18, 2024 5:30 PM
Last edited by: Nick Durbin
Last edited time: July 29, 2024 7:24 PM

# Videos

[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)

[Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU&t=95s)

[Create a Large Language Model from Scratch with Python – Tutorial](https://www.youtube.com/watch?v=UU1WVnMk4E8)

# Papers

- Bengio et al. 2003 MLP language model paper (pdf): [https://www.jmlr.org/papers/volume3/b...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmlOWWd1WGZjcmEyUUZhNHgxRVJpUmxFQkU2UXxBQ3Jtc0trNlhCZ01tWndIWWZldURrQkhoRk9aeEE3X2RveE5KTzdIal81RXppSW5YQVoxeXVMNkdXUnF4UHpnSEtVVkZLV0RrczJyMkVjS1FqR0pQRTREc3lQcUFsSWRUODFKQW9rSlNlcDE4dzR6Uk81TExudw&q=https%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fbengio03a%2Fbengio03a.pdf&v=TCH_1BHY58I)

- "Kaiming init" paper: [https://arxiv.org/abs/1502.01852](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFV6OXhuamY5ZlA0cWdMVnhoN21EZWkyQ2p1d3xBQ3Jtc0tuQm4xV191ODFyYi1fZ1pMdmRBSF9rSG9Cc2cyRExmaU9kM3BNQzVUQ04yQzBIVmNFMERLOHRtNFg1anh3T1lBOUxQQXphUEhTLXZvWkRTUmxqQjlwdGFBeFl1ZFVfT0xtRnZRY2txaTN5dGozbk8tYw&q=https%3A%2F%2Farxiv.org%2Fabs%2F1502.01852&v=P6sfmUTpUmc)

- BatchNorm paper: [https://arxiv.org/abs/1502.03167](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVBhTVZGVklyY2preWJIMWJwZXdDQVZ4MDNQQXxBQ3Jtc0traTRVeFgtWEhmemZqcGtyU0tiaTRVVF9WNnhjeFpSM3JCaEtaS3MtSjJvTGJ2ZTYwYkZwTE9Mc2U5d1R0b2diQm9ZZHpnXzdUci1yVjh4NnVSZy1VQ2hZcHZrSWM0WWJRN2ZCSWRVUHNIVU9OOTNlaw&q=https%3A%2F%2Farxiv.org%2Fabs%2F1502.03167&v=P6sfmUTpUmc)

- Bessel’s Correction: [http://math.oxford.emory.edu/site/mat...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa3hSaUNURzlGdWw2cy1ZMWVZSUtWRHhzczBlQXxBQ3Jtc0tsRVc5OVJvc3JwQ0tJWGRzUFJxak8xandDU2RfS0NuTnNmU3RsSlI1djJIVVJHaHJ1Sjl6ZGJQM2lYV0U4Wlg3LWxQUVlDelpxbGhJVDN4Nlk3UVlBM1l2dlhKZWJ5YWZfR2FUVk1MY0pxT0NyZHFCcw&q=http%3A%2F%2Fmath.oxford.emory.edu%2Fsite%2Fmath117%2FbesselCorrection%2F&v=q8SA3rM6ckI)

- Good paper illustrating some of the problems with batchnorm in practice: [https://arxiv.org/abs/2105.07576](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVlINVctWkpUM2ZuX1FZNDFNM0FNeTlQbVdtQXxBQ3Jtc0tuWktpZDZaZ2ZTWWVOYUROOV9yOE1TX3ZVN2U1eU9EZ1NJcGQyNkFEN0VETmNlZ3lpV3piY2ZkLVVOM1lBYzRCMlV5MWxzYVBCVFNmSmllclZRQk5ocVJQUzZsRThJYXhhNXNvQkFzU0l4RnREZWJLTQ&q=https%3A%2F%2Farxiv.org%2Fabs%2F2105.07576&v=P6sfmUTpUmc)

- WaveNet 2016 from DeepMind: [https://arxiv.org/abs/1609.03499](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWdRdjEyWi00bmNIRVZVYWpScjFxc3FUSS1wZ3xBQ3Jtc0trZmNKT3c5WmNlT1IzV2RsdHpJMGJzaEh2aXM2T2h4LVNUWTI3SmZ4Q0hBd0Z6QTBJNHBucE9oTlZ3bnIxN2tua3NpZUI2ekhhbnQ5ZFZsUmZxaDB0eG53Q0pVMUtLdU9rV0M4YUlnbXFRNHBBY3ZzQQ&q=https%3A%2F%2Farxiv.org%2Fabs%2F1609.03499&v=t3YJ5hKiMQ0)

- Attention is All You Need paper: [https://arxiv.org/abs/1706.03762](https://arxiv.org/pdf/1706.03762)

- Improving Language Understanding by Generative Pre-Training: [https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

- OpenAI GPT-2 paper: [https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

- OpenAI GPT-3 paper: [https://arxiv.org/pdf/2005.14165](https://arxiv.org/pdf/2005.14165)

- OpenAI ChatGPT blog post: [https://openai.com/blog/chatgpt/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbmVhQ1FXUFNuM2UxQmx5LTFaU21LcXlLeGpvUXxBQ3Jtc0tua2J5RWRCd1ZHRmlEek1Rck1IYml4T0RTNi1sOHlKRnB3ajQyUnBNOW1GYVdtVzF0NmlXTHRoaGE2em9lWEtmSXkxLXZ2ODQwaEkwWkYtTjdENkc5ZFNodWkyS0JpOEUtS1JUZ2pvZ0JiZmUtMnZjdw&q=https%3A%2F%2Fopenai.com%2Fblog%2Fchatgpt%2F&v=kCc8FmEb1nY)

- The GPU I'm training the model on is from Lambda GPU Cloud, I think the best and easiest way to spin up an on-demand GPU instance in the cloud that you can ssh to: [https://lambdalabs.com](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXdaNFdQY1VBWGlSRFRCcFhlVGZHQ2ZWSkRuQXxBQ3Jtc0ttWmg0Y3RvUDJ6V2haZzF3ejBzbXMtYUtMNURpT0NYR0ZLMDJ0UVRYcmRleV92bDE3SVM0cFdjXzdIRmlKYVNJVGNNWXdpNEJTSDFtc2dhQUJZeFFEWHdPbm15UEpnOTdObzNqUGVSenZOSDhxaUw3VQ&q=https%3A%2F%2Flambdalabs.com%2F&v=kCc8FmEb1nY)